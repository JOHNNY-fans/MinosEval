{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "import time\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 加载NLI模型和tokenizer，指定在第0块GPU上运行\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_name = \"../../models/xlm-roberta-large-xnli\"\n",
    "model_name = \"../../models/mDeBERTa-v3-base-mnli-xnli\"\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli_judge(sentence_list, candidate_lists, batch_size=32):\n",
    "    \"\"\"\n",
    "    NLI任务的推理函数，输入句子列表和候选句子列表，返回每个句子与候选句子列表的推理判断。\n",
    "    \n",
    "    参数：\n",
    "    - sentence_list: List[str]，基准句子列表。\n",
    "    - candidate_lists: List[List[str]]，每个基准句子对应的候选句子列表。\n",
    "    - batch_size: int，批量大小。\n",
    "    \n",
    "    返回：\n",
    "    - List[List[str]]，每个基准句子与候选句子的推理判断结果（entailment、neutral、contradiction）。\n",
    "    \"\"\"\n",
    "    labels = [\"contradiction\", \"neutral\",\"entailment\"] if 'mDeBERTa' not in model_name else [\"entailment\", \"neutral\",\"contradiction\"]\n",
    "    \n",
    "    # 将输入拉平成两个列表\n",
    "    flattened_sentences = []\n",
    "    flattened_candidates = []\n",
    "    sentence_lengths = []\n",
    "\n",
    "    for sentence, candidates in zip(sentence_list, candidate_lists):\n",
    "        flattened_sentences.extend([sentence] * len(candidates))\n",
    "        flattened_candidates.extend(candidates)\n",
    "        sentence_lengths.append(len(candidates))\n",
    "\n",
    "    # 批量计算NLI推理结果\n",
    "    all_results = []\n",
    "    all_soft_results = []\n",
    "    for i in range(0, len(flattened_sentences), batch_size):\n",
    "        batch_sentences = flattened_sentences[i:i + batch_size]\n",
    "        batch_candidates = flattened_candidates[i:i + batch_size]\n",
    "\n",
    "        encoded_input = nli_tokenizer(batch_sentences, batch_candidates,\n",
    "                                      return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = nli_model(**encoded_input)\n",
    "            soft_outputs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "            all_results.extend([labels[pred] for pred in predictions])\n",
    "            soft_outputs = soft_outputs.tolist()\n",
    "            all_soft_results.extend([soft_pred[labels.index('entailment')] -soft_pred[labels.index('contradiction')] for soft_pred in soft_outputs])\n",
    "            # all_soft_results.extend(soft_outputs.tolist())\n",
    "\n",
    "    # 将结果映射回原始结构\n",
    "    mapped_results, mapped_soft_results = [], []\n",
    "    idx = 0\n",
    "    for length in sentence_lengths:\n",
    "        mapped_results.append(all_results[idx:idx + length])\n",
    "        mapped_soft_results.append(all_soft_results[idx:idx+length])\n",
    "        idx += length\n",
    "\n",
    "    return mapped_results, mapped_soft_results\n",
    "\n",
    "\n",
    "def sts_judge(sentence_list, candidate_lists, batch_size=32):\n",
    "    \"\"\"\n",
    "    STS任务的相似度计算函数，输入句子列表和候选句子列表，返回相似度分数列表。\n",
    "    \n",
    "    参数：\n",
    "    - sentence_list: List[str]，基准句子列表。\n",
    "    - candidate_lists: List[List[str]]，每个基准句子对应的候选句子列表。\n",
    "    - batch_size: int，批量大小。\n",
    "    \n",
    "    返回：\n",
    "    - List[List[float]]，每个基准句子与候选句子的相似度分数列表。\n",
    "    \"\"\"\n",
    "    # 将输入拉平成两个列表\n",
    "    flattened_sentences = []\n",
    "    flattened_candidates = []\n",
    "    sentence_lengths = []\n",
    "\n",
    "    for sentence, candidates in zip(sentence_list, candidate_lists):\n",
    "        flattened_sentences.extend([sentence] * len(candidates))\n",
    "        flattened_candidates.extend(candidates)\n",
    "        sentence_lengths.append(len(candidates))\n",
    "\n",
    "    # 批量计算相似度\n",
    "    all_similarities = []\n",
    "    for i in range(0, len(flattened_sentences), batch_size):\n",
    "        batch_sentences = flattened_sentences[i:i + batch_size]\n",
    "        batch_candidates = flattened_candidates[i:i + batch_size]\n",
    "\n",
    "        # 编码基准句子和候选句子\n",
    "        sentence_embeddings = sts_model.encode(batch_sentences, convert_to_tensor=True).to(device)\n",
    "        candidate_embeddings = sts_model.encode(batch_candidates, convert_to_tensor=True).to(device)\n",
    "\n",
    "        # 计算余弦相似度\n",
    "        similarities = util.cos_sim(sentence_embeddings, candidate_embeddings).diagonal().cpu().numpy()\n",
    "        all_similarities.extend(similarities.tolist())\n",
    "    \n",
    "\n",
    "    # 将结果映射回原始结构\n",
    "    mapped_results = []\n",
    "    idx = 0\n",
    "    for length in sentence_lengths:\n",
    "        mapped_results.append(all_similarities[idx:idx + length])\n",
    "        idx += length\n",
    "\n",
    "    return mapped_results\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x, t=1.0):\n",
    "    x = np.array(x) / t \n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nli_points_score(response_dict, points):\n",
    "    \"\"\"\n",
    "    输入一个包含多个模型 response 的字典，以及 points 列表。\n",
    "    返回每个模型对应的 NLI 得分。\n",
    "    \"\"\"\n",
    "    model_names = list(response_dict.keys())\n",
    "    responses = list(response_dict.values())\n",
    "\n",
    "    # 批量处理所有模型 response 与 points 的蕴含关系\n",
    "    nli_results, nli_soft_results = nli_judge(responses, [points] * len(responses))\n",
    "    \n",
    "    # 映射回模型名称，并计算得分\n",
    "    scores = {\n",
    "        model_name: (sum(1 for result in nli_result if result == \"entailment\") - sum(1 for result in nli_result if result == \"contradiction\")) / len(points)\n",
    "        for model_name, nli_result in zip(model_names, nli_results)\n",
    "    }\n",
    "\n",
    "    soft_scores = {\n",
    "        model_name: sum(nli_soft_results) / len(points)\n",
    "        for model_name, nli_soft_results in zip(model_names, nli_soft_results)\n",
    "    }\n",
    "    \n",
    "    return scores, soft_scores\n",
    "\n",
    "\n",
    "# 计算 examples 的 STS 得分\n",
    "def calculate_sts_example_score(response_dict, examples):\n",
    "    \"\"\"\n",
    "    输入一个包含多个模型 response 的字典，以及 examples 字典。\n",
    "    返回每个模型对应的 STS 得分。\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    example_texts = list(examples.keys())\n",
    "\n",
    "    for model_name, response in response_dict.items():\n",
    "        # 使用 STS 判断 response 和每个 example 的相似度\n",
    "        sts_scores = sts_judge([response], [example_texts])\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(\"Response:\", response)\n",
    "        print(\"Examples:\", example_texts)\n",
    "        print(\"STS Scores:\", sts_scores)\n",
    "\n",
    "        # 找到最高相似度的 example\n",
    "        max_score_index = sts_scores[0].index(max(sts_scores[0]))\n",
    "        # 返回该 example 对应的分数\n",
    "        scores[model_name] = examples[example_texts[max_score_index]] / max(examples.values())\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def calculate_critic_similarity_weight(critic, answer_critic):\n",
    "    \"\"\"\n",
    "    计算每个模型 critic 与 answer_critic 的相似度并生成加权得分。\n",
    "    \n",
    "    参数：\n",
    "    - critic: dict，每个模型名称对应的列表，包含对模型回复的评价。\n",
    "    - answer_critic: List[str]，标准答案的评价列表。\n",
    "    \n",
    "    返回：\n",
    "    - dict，每个模型的平均加权评分。\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    # 遍历每个模型的 critic\n",
    "    for model_name, model_critic in critic.items():\n",
    "        max_similarities = []\n",
    "\n",
    "        # 对于每个 critic 项，计算与 answer_critic 每条评价的相似度，取最大值\n",
    "        for critic_item in model_critic:\n",
    "            sts_results = sts_judge([critic_item], [answer_critic])\n",
    "            # print(sts_results)\n",
    "            max_similarity = max(sts_results[0])  # 取与 answer_critic 最相似的值\n",
    "            max_similarities.append(1.0-max_similarity)\n",
    "\n",
    "        # 计算 softmax 权重，确保和为1\n",
    "        # weights = sigmoid(max_similarities)\n",
    "        weights = np.clip(max_similarities,0.,2.)\n",
    "\n",
    "        # 计算加权评分\n",
    "        total_weighted_score = sum(-1 * weight for weight in weights)\n",
    "        \n",
    "        # 平均得分\n",
    "        scores[model_name] = total_weighted_score / len(model_critic)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "samples = []\n",
    "with open(\"../../data/align/fact/align_points.json\", 'r', encoding=\"utf-8-sig\") as file:\n",
    "    data = json.loads(file.read())\n",
    "    samples = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 NLI points 得分\n",
    "for item in tqdm(samples):\n",
    "    response = item['response']\n",
    "    points = item['points']\n",
    "    points_score, points_soft_score = calculate_nli_points_score(response, points)\n",
    "    item['points_score'] = points_soft_score\n",
    "\n",
    "with open(\"../../data/align/fact/align_points_\"+model_name.split('/')[-1]+\".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(samples, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
